{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a51b3e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ipykernel\n",
    "import pytesseract as py\n",
    "import unstructured as un\n",
    "from pathlib import Path\n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "os.environ[\"PATH\"] += os.pathsep + r\"C:\\Program Files\\poppler\\poppler-24.08.0\\Library\\bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "166d0b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pdf_files():\n",
    "    \"\"\"Returns pdf path of all pdf files\"\"\"\n",
    "    corpus_path = \"corpus\"\n",
    "    pdf_files = []\n",
    "    for root, dirs, files in os.walk(corpus_path):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(\".pdf\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                pdf_files.append(file_path)\n",
    "    return pdf_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ee26a81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "from unstructured.documents.elements import Text\n",
    "import pytesseract\n",
    "\n",
    "def extract_text_with_metadata(pdf_path):\n",
    "    pdf_path = Path(pdf_path)\n",
    "\n",
    "    pdf_elements = partition_pdf(\n",
    "        filename=str(pdf_path),\n",
    "        strategy=\"hi_res\",\n",
    "        extract_images_in_pdf=False\n",
    "    )\n",
    "\n",
    "    page_data = {}\n",
    "    for ele in pdf_elements:\n",
    "        if isinstance(ele, Text) and ele.text.strip():\n",
    "            meta = ele.metadata.to_dict() if ele.metadata else {}\n",
    "            page_num = meta.get(\"page_number\", \"unknown\")\n",
    "\n",
    "            # Group text by page number\n",
    "            page_data.setdefault(page_num, []).append(ele.text.strip())\n",
    "\n",
    "    # Merge text chunks for each page\n",
    "    for page in page_data:\n",
    "        page_data[page] = \"\\n\".join(page_data[page])\n",
    "\n",
    "    return page_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "31df60ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from unstructured.documents.elements import Image\n",
    "\n",
    "def extract_images_with_metadata(pdf_path):\n",
    "    pdf_path = Path(pdf_path)\n",
    "\n",
    "    pdf_elements = partition_pdf(\n",
    "        filename=str(pdf_path),\n",
    "        strategy=\"hi_res\",\n",
    "        infer_table_structure=True,\n",
    "        extract_image_block_types=[\"Image\", \"Figure\", \"Table\"],\n",
    "        extract_image_block_to_payload=True,\n",
    "        chunking_strategy=None,\n",
    "    )\n",
    "\n",
    "    image_data = []\n",
    "    for ele in pdf_elements:\n",
    "        if isinstance(ele, Image):\n",
    "            meta = ele.metadata.to_dict() if ele.metadata else {}\n",
    "            image_data.append({\n",
    "                \"pdf_name\": pdf_path.name,\n",
    "                \"page_number\": meta.get(\"page_number\"),\n",
    "                \"image_base64\": meta.get(\"image_base64\"),  # Base64 image data\n",
    "                # \"coordinates\": meta.get(\"coordinates\")\n",
    "            })\n",
    "\n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e270b1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_pdfs():\n",
    "    \"\"\"Processes all PDFs in the corpus folder and extracts text and images.\"\"\"\n",
    "    pdf_paths = read_pdf_files()\n",
    "    all_results = {}\n",
    "\n",
    "    for pdf_path in pdf_paths:\n",
    "        print(f\"\\nProcessing: {pdf_path}\")\n",
    "\n",
    "        # Extract text\n",
    "        text_data = extract_text_with_metadata(pdf_path)\n",
    "\n",
    "        # Extract images\n",
    "        image_data = extract_images_with_metadata(pdf_path)\n",
    "\n",
    "        # Store both in results\n",
    "        all_results[pdf_path] = {\n",
    "            \"text\": text_data,\n",
    "            \"images\": image_data\n",
    "        }\n",
    "\n",
    "        for page, text in text_data.items():\n",
    "            print(f\"\\n--- {pdf_path} | Page {page} ---\")\n",
    "            print(text[:500], \"...\" if len(text) > 500 else \"\")\n",
    "\n",
    "        print(f\"\\nExtracted {len(image_data)} images from {pdf_path}\\n\")\n",
    "\n",
    "    return all_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9729ab87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
